{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbloewencolon/Psychedelic-Trip-Generator/blob/main/Classification_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24-t0XrJzOP1"
      },
      "source": [
        "## Data Modeling\n",
        "With our cleaned data in hand, we now want to train some models on our data set. In particular, we want to see how well they can predict drug category based on the processed reports. Precision will be our metric, as we want a model that is able to reproduce similar reports itself.\n",
        "\n",
        "### Step 1: Importing Libraries\n",
        "This section is about loading all the necessary libraries to conduct the project.\n",
        "\n",
        "General Libraries like itertools and re for general programming tasks.\n",
        "Natural Language Processing Libraries such as nltk and gensim for text processing and modeling.\n",
        "Machine Learning Libraries like sklearn, tensorflow, xgboost for building, training, and evaluating models.\n",
        "Data Handling Libraries like numpy, pandas for managing and manipulating data.\n",
        "Visualization Libraries such as matplotlib, seaborn for creating plots.\n",
        "Imbalanced Learning Library imblearn to handle imbalanced datasets.\n",
        "Word Cloud Library wordcloud for visualizing word frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fbg8J8KKcGTp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "d9db546c-d889-440b-b347-c64f8df2e8c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.65.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2023.7.18)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (23.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-53cc3286f760>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLimeTextExplainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lime.text'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "!pip install numpy --upgrade\n",
        "!pip install lime\n",
        "\n",
        "import itertools\n",
        "import re\n",
        "from ast import literal_eval\n",
        "\n",
        "import pickle\n",
        "import gensim\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import xgboost as xgb\n",
        "import random\n",
        "import joblib\n",
        "from gensim import corpora\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedShuffleSplit\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, FunctionTransformer\n",
        "from wordcloud import WordCloud\n",
        "from xgboost import XGBClassifier\n",
        "from lime.text import LimeTextExplainer\n",
        "from random import randint\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9wbz4KHzOP5"
      },
      "source": [
        "## Step 2: Data Loading and Preprocessing\n",
        "This part loads the dataset and provides information about its structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G5SEabEci28",
        "outputId": "0f527cd2-5525-46e5-e8a0-422fd743cb82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 67875 entries, 0 to 67874\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   drug              67875 non-null  object\n",
            " 1   dosage            66103 non-null  object\n",
            " 2   delivery          65447 non-null  object\n",
            " 3   weight            67875 non-null  int64 \n",
            " 4   gender            67875 non-null  object\n",
            " 5   report            67875 non-null  object\n",
            " 6   processed_report  67875 non-null  object\n",
            " 7   mixed             67875 non-null  int64 \n",
            " 8   drug_category     67875 non-null  object\n",
            "dtypes: int64(2), object(7)\n",
            "memory usage: 4.7+ MB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/processed.csv')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cDsRNYNU8wOP",
        "outputId": "c84f4ff4-753a-48f8-d89b-fc2009792549"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  drug    dosage     delivery  weight gender  \\\n",
              "0                 mdpv       NaN  insufflated     140   male   \n",
              "1                crack  repeated       smoked     165   male   \n",
              "2        methcathinone     10 mg           IV     135   male   \n",
              "3              jwh-018                 smoked     209   male   \n",
              "4  pharms - pregabalin                            170   male   \n",
              "\n",
              "                                              report  \\\n",
              "0  MDPV, Over a Two-Month PeriodI thought I'd sha...   \n",
              "1  I'll start this story with a bit of background...   \n",
              "2  I hate the name of this drug. Impossible for m...   \n",
              "3  Me - Male (95kg, 29 y/o, moderate experience o...   \n",
              "4  GBL AddictI was thinking of writing this for a...   \n",
              "\n",
              "                                    processed_report  mixed  \\\n",
              "0  ['mdpv', 'over', 'a', 'twomonth', 'periodi', '...      1   \n",
              "1  ['i', 'll', 'start', 'this', 'story', 'with', ...      0   \n",
              "2  ['i', 'hate', 'the', 'name', 'of', 'this', 'dr...      1   \n",
              "3  ['me', 'male', '95kg', '29', 'yo', 'moderate',...      1   \n",
              "4  ['gbl', 'addicti', 'wa', 'thinking', 'of', 'wr...      1   \n",
              "\n",
              "           drug_category  \n",
              "0  Entactogen/Empathogen  \n",
              "1              Stimulant  \n",
              "2              Stimulant  \n",
              "3            Cannabinoid  \n",
              "4         Pharmaceutical  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-05c7cd20-f613-4569-adc7-4f44f9566118\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drug</th>\n",
              "      <th>dosage</th>\n",
              "      <th>delivery</th>\n",
              "      <th>weight</th>\n",
              "      <th>gender</th>\n",
              "      <th>report</th>\n",
              "      <th>processed_report</th>\n",
              "      <th>mixed</th>\n",
              "      <th>drug_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mdpv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>insufflated</td>\n",
              "      <td>140</td>\n",
              "      <td>male</td>\n",
              "      <td>MDPV, Over a Two-Month PeriodI thought I'd sha...</td>\n",
              "      <td>['mdpv', 'over', 'a', 'twomonth', 'periodi', '...</td>\n",
              "      <td>1</td>\n",
              "      <td>Entactogen/Empathogen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>crack</td>\n",
              "      <td>repeated</td>\n",
              "      <td>smoked</td>\n",
              "      <td>165</td>\n",
              "      <td>male</td>\n",
              "      <td>I'll start this story with a bit of background...</td>\n",
              "      <td>['i', 'll', 'start', 'this', 'story', 'with', ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Stimulant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>methcathinone</td>\n",
              "      <td>10 mg</td>\n",
              "      <td>IV</td>\n",
              "      <td>135</td>\n",
              "      <td>male</td>\n",
              "      <td>I hate the name of this drug. Impossible for m...</td>\n",
              "      <td>['i', 'hate', 'the', 'name', 'of', 'this', 'dr...</td>\n",
              "      <td>1</td>\n",
              "      <td>Stimulant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jwh-018</td>\n",
              "      <td></td>\n",
              "      <td>smoked</td>\n",
              "      <td>209</td>\n",
              "      <td>male</td>\n",
              "      <td>Me - Male (95kg, 29 y/o, moderate experience o...</td>\n",
              "      <td>['me', 'male', '95kg', '29', 'yo', 'moderate',...</td>\n",
              "      <td>1</td>\n",
              "      <td>Cannabinoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pharms - pregabalin</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>170</td>\n",
              "      <td>male</td>\n",
              "      <td>GBL AddictI was thinking of writing this for a...</td>\n",
              "      <td>['gbl', 'addicti', 'wa', 'thinking', 'of', 'wr...</td>\n",
              "      <td>1</td>\n",
              "      <td>Pharmaceutical</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05c7cd20-f613-4569-adc7-4f44f9566118')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-2582bb05-93e8-4666-bb53-91198d7b779d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2582bb05-93e8-4666-bb53-91198d7b779d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-2582bb05-93e8-4666-bb53-91198d7b779d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05c7cd20-f613-4569-adc7-4f44f9566118 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05c7cd20-f613-4569-adc7-4f44f9566118');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VugQc8yBzOP6"
      },
      "source": [
        "Looks like our data was imported cleanly and has been randomized.\n",
        "\n",
        "## Data Preperation for Models\n",
        "Our goal is to train at least three models and that compare which achives the highest precision. Our three models are a logistic regression, a random forest classifier, and an XGBoost model.\n",
        "\n",
        "We are going to start by creating a Word2Vec model to use in our more complex multiclassifcation problems. Imagine the words in psychedelic trip reports are like ingredients in a complex recipe. Word2Vec helps translate these words into a language that a computer, such as a Random Forest Classifier (RFC), understands. It’s like having a taste expert who knows the flavor of each ingredient (Word2Vec) working with a skilled chef (RFC) to create a dish. Together, they recognize unique flavors and combinations in trip reports, allowing us to identify specific experiences or drug categories more accurately."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert string representations of lists into actual lists\n",
        "#df['processed_report'] = df['processed_report'].apply(literal_eval)\n",
        "\n",
        "# Now flatten the lists\n",
        "#df['processed_report'] = df['processed_report'].apply(lambda x: [word for sublist in x for word in sublist])\n",
        "\n",
        "# Verify the conversion\n",
        "#print(type(df['processed_report'].iloc[0]))\n"
      ],
      "metadata": {
        "id": "aDzYWGwr_Tf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "H755_cGFfjTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert a report into a vector\n",
        "def report_to_vector(report, model):\n",
        "    report_vec = []\n",
        "    numw = 0\n",
        "    for word in report:\n",
        "        try:\n",
        "            if numw == 0:\n",
        "                report_vec = model.wv[word]\n",
        "            else:\n",
        "                report_vec = np.add(report_vec, model.wv[word])\n",
        "            numw+=1\n",
        "        except:\n",
        "            pass\n",
        "    return np.asarray(report_vec) / numw if numw != 0 else np.zeros(model.vector_size)"
      ],
      "metadata": {
        "id": "n4Sw5Uex_q0d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2VecVectorizer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.size = model.vector_size\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return vectorize_reports(X, self.model)"
      ],
      "metadata": {
        "id": "-lk8DeP6_tKp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_reports = df['processed_report'].tolist()\n",
        "\n",
        "# Train a Word2Vec model\n",
        "#word2vec = Word2Vec(sentences=tokenized_reports, vector_size=100, window=5, min_count=5, workers=4)"
      ],
      "metadata": {
        "id": "HRoEZuLT_yKN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SMz4kOihhShH",
        "outputId": "786ed6b5-6581-4f02-be1e-812dd724f26e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  drug    dosage     delivery  weight gender  \\\n",
              "0                 mdpv       NaN  insufflated     140   male   \n",
              "1                crack  repeated       smoked     165   male   \n",
              "2        methcathinone     10 mg           IV     135   male   \n",
              "3              jwh-018                 smoked     209   male   \n",
              "4  pharms - pregabalin                            170   male   \n",
              "\n",
              "                                              report  \\\n",
              "0  MDPV, Over a Two-Month PeriodI thought I'd sha...   \n",
              "1  I'll start this story with a bit of background...   \n",
              "2  I hate the name of this drug. Impossible for m...   \n",
              "3  Me - Male (95kg, 29 y/o, moderate experience o...   \n",
              "4  GBL AddictI was thinking of writing this for a...   \n",
              "\n",
              "                                    processed_report  mixed  \\\n",
              "0  ['mdpv', 'over', 'a', 'twomonth', 'periodi', '...      1   \n",
              "1  ['i', 'll', 'start', 'this', 'story', 'with', ...      0   \n",
              "2  ['i', 'hate', 'the', 'name', 'of', 'this', 'dr...      1   \n",
              "3  ['me', 'male', '95kg', '29', 'yo', 'moderate',...      1   \n",
              "4  ['gbl', 'addicti', 'wa', 'thinking', 'of', 'wr...      1   \n",
              "\n",
              "           drug_category  \n",
              "0  Entactogen/Empathogen  \n",
              "1              Stimulant  \n",
              "2              Stimulant  \n",
              "3            Cannabinoid  \n",
              "4         Pharmaceutical  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-f11a2964-ff44-4fb9-aeda-0db2cd6194f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drug</th>\n",
              "      <th>dosage</th>\n",
              "      <th>delivery</th>\n",
              "      <th>weight</th>\n",
              "      <th>gender</th>\n",
              "      <th>report</th>\n",
              "      <th>processed_report</th>\n",
              "      <th>mixed</th>\n",
              "      <th>drug_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mdpv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>insufflated</td>\n",
              "      <td>140</td>\n",
              "      <td>male</td>\n",
              "      <td>MDPV, Over a Two-Month PeriodI thought I'd sha...</td>\n",
              "      <td>['mdpv', 'over', 'a', 'twomonth', 'periodi', '...</td>\n",
              "      <td>1</td>\n",
              "      <td>Entactogen/Empathogen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>crack</td>\n",
              "      <td>repeated</td>\n",
              "      <td>smoked</td>\n",
              "      <td>165</td>\n",
              "      <td>male</td>\n",
              "      <td>I'll start this story with a bit of background...</td>\n",
              "      <td>['i', 'll', 'start', 'this', 'story', 'with', ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Stimulant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>methcathinone</td>\n",
              "      <td>10 mg</td>\n",
              "      <td>IV</td>\n",
              "      <td>135</td>\n",
              "      <td>male</td>\n",
              "      <td>I hate the name of this drug. Impossible for m...</td>\n",
              "      <td>['i', 'hate', 'the', 'name', 'of', 'this', 'dr...</td>\n",
              "      <td>1</td>\n",
              "      <td>Stimulant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jwh-018</td>\n",
              "      <td></td>\n",
              "      <td>smoked</td>\n",
              "      <td>209</td>\n",
              "      <td>male</td>\n",
              "      <td>Me - Male (95kg, 29 y/o, moderate experience o...</td>\n",
              "      <td>['me', 'male', '95kg', '29', 'yo', 'moderate',...</td>\n",
              "      <td>1</td>\n",
              "      <td>Cannabinoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pharms - pregabalin</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>170</td>\n",
              "      <td>male</td>\n",
              "      <td>GBL AddictI was thinking of writing this for a...</td>\n",
              "      <td>['gbl', 'addicti', 'wa', 'thinking', 'of', 'wr...</td>\n",
              "      <td>1</td>\n",
              "      <td>Pharmaceutical</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f11a2964-ff44-4fb9-aeda-0db2cd6194f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-72c4fe91-2139-44a0-941b-5272e5a0b1b1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-72c4fe91-2139-44a0-941b-5272e5a0b1b1')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-72c4fe91-2139-44a0-941b-5272e5a0b1b1 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f11a2964-ff44-4fb9-aeda-0db2cd6194f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f11a2964-ff44-4fb9-aeda-0db2cd6194f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word2vec.save(\"/content/drive/MyDrive/Colab Notebooks/Data/word2vec_model.model\")"
      ],
      "metadata": {
        "id": "zf6wciZ7aUdt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step sets our dependent and independent variables for our models. Additionally, the target variable (drug_category) is encoded to numerical form."
      ],
      "metadata": {
        "id": "cdP02fz3_T3E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YOepzAn9JbR_"
      },
      "outputs": [],
      "source": [
        "# Define y\n",
        "y = df['drug_category']\n",
        "\n",
        "# Encode the labels in y\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "X = df['processed_report']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Pipelines\n",
        "We'll define three pipelines, starting with a Logistic Regression as a baseline, and then Random Forest, and XGBoost to see if we can get imrpovements. Because of our class imbalance, we will include SMOTE for each. While the logistic Regression will use TF-IDF, while Random Forest and XGBoost will later use the Word2Vec we created earlier.\n",
        "\n",
        "* **TF-IDF**: Helps transform text into a numerical format the model can understand.\n",
        "* **SMOTE**: Handles class imbalance."
      ],
      "metadata": {
        "id": "kFADxcOY2cdj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_7AH67kKOIJe"
      },
      "outputs": [],
      "source": [
        "def to_string_func(x):\n",
        "    return [' '.join(i) if isinstance(i, list) else i for i in x]\n",
        "\n",
        "# Define pipeline for Logistic Regression with TF-IDF\n",
        "pipeline_lr = ImbPipeline([\n",
        "    ('to_string', FunctionTransformer(to_string_func)),\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('smote', SMOTE()),\n",
        "    ('clf', LogisticRegression(max_iter=500, C=1.0, solver='saga', n_jobs=-1))\n",
        "])\n",
        "\n",
        "# Define pipeline for RFC and XGB (SMOTE included; Word2Vec will be applied later)\n",
        "pipeline_rf = ImbPipeline([\n",
        "    ('smote', SMOTE()),\n",
        "    ('clf', RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1))\n",
        "])\n",
        "\n",
        "pipeline_xgb = ImbPipeline([\n",
        "    ('smote', SMOTE()),\n",
        "    ('clf', XGBClassifier(n_estimators=100, max_depth=3, n_jobs=-1, eval_metric='mlogloss'))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNLdyfGPzOP7"
      },
      "source": [
        "## Data Splitting and Stratification\n",
        "Next we'll split and stratify the data for the Logistic Regression model. For the Random Forest and XGBoost models, we'll load the Word2Vec-transformed data and stratify that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G8Fra2jtOKw1"
      },
      "outputs": [],
      "source": [
        "# Path to the saved model\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/Data/word2vec_model.model\"\n",
        "\n",
        "# Load the model\n",
        "word2vec = Word2Vec.load(path)\n",
        "\n",
        "# Split and stratify data for Logistic Regression\n",
        "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
        "\n",
        "def vectorize_reports(tokenized_reports, word2vec_model):\n",
        "    vectorized_reports = []\n",
        "    for report in tokenized_reports:\n",
        "        report_vec = np.mean([word2vec_model.wv[word] for word in report if word in word2vec_model.wv], axis=0)\n",
        "        vectorized_reports.append(report_vec)\n",
        "    return np.array(vectorized_reports)\n",
        "\n",
        "X_word2vec = vectorize_reports(tokenized_reports, word2vec)\n",
        "X_word2vec = np.vstack(X_word2vec)\n",
        "\n",
        "# Split and stratify data for RFC and XGB\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "train_index, test_index = next(sss.split(X_word2vec, y_encoded))\n",
        "X_train_w2v, X_test_w2v = X_word2vec[train_index], X_word2vec[test_index]\n",
        "y_train_w2v, y_test_w2v = y_encoded[train_index], y_encoded[test_index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPysCCS7zOP9"
      },
      "source": [
        "## Training, Prediction, and Comparison\n",
        "Here, we'll train the models, make predictions, and compare the results. This can be done by creating functions train_and_predict and compare_results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_predict(pipeline, X_train, y_train, X_test):\n",
        "    # Fit the pipeline\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the train and test set\n",
        "    y_train_pred = pipeline.predict(X_train)\n",
        "    y_test_pred = pipeline.predict(X_test)\n",
        "\n",
        "    return y_train_pred, y_test_pred\n",
        "\n",
        "def compare_results(model_name, y_train, y_train_pred, y_test, y_test_pred, label_encoder):\n",
        "    target_names = label_encoder.classes_\n",
        "\n",
        "    print(f\"\\n{model_name} - Train Classification Report:\")\n",
        "    print(classification_report(y_train, y_train_pred, target_names=target_names, zero_division=1))\n",
        "    print(f\"{model_name} - Test Classification Report:\")\n",
        "    print(classification_report(y_test, y_test_pred, target_names=target_names, zero_division=1))\n"
      ],
      "metadata": {
        "id": "wj7DW6hw4VlN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UVm0JQdrlCp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19d17e15-a747-4b66-ff55-41af7a086260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression - Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.51      0.56      4622\n",
            "           1       0.54      0.64      0.59      1809\n",
            "           2       0.68      0.87      0.77      2116\n",
            "           3       0.78      0.85      0.82      5166\n",
            "           4       0.75      0.91      0.82      2814\n",
            "           5       0.74      0.88      0.81      1967\n",
            "           6       0.82      0.75      0.78      4999\n",
            "           7       0.81      0.77      0.79      5231\n",
            "           8       0.89      0.85      0.87     22690\n",
            "           9       0.74      0.74      0.74      2886\n",
            "\n",
            "    accuracy                           0.80     54300\n",
            "   macro avg       0.74      0.78      0.75     54300\n",
            "weighted avg       0.80      0.80      0.80     54300\n",
            "\n",
            "Logistic Regression - Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.43      1155\n",
            "           1       0.31      0.33      0.32       452\n",
            "           2       0.56      0.70      0.62       529\n",
            "           3       0.71      0.77      0.74      1292\n",
            "           4       0.69      0.80      0.74       704\n",
            "           5       0.66      0.76      0.70       492\n",
            "           6       0.71      0.64      0.67      1250\n",
            "           7       0.69      0.68      0.68      1308\n",
            "           8       0.84      0.81      0.82      5672\n",
            "           9       0.61      0.60      0.60       721\n",
            "\n",
            "    accuracy                           0.71     13575\n",
            "   macro avg       0.62      0.65      0.63     13575\n",
            "weighted avg       0.71      0.71      0.71     13575\n",
            "\n",
            "\n",
            "Random Forest - Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.71      0.71      4622\n",
            "           1       0.67      0.75      0.71      1809\n",
            "           2       0.81      0.86      0.84      2116\n",
            "           3       0.83      0.89      0.86      5166\n",
            "           4       0.83      0.90      0.87      2814\n",
            "           5       0.83      0.90      0.87      1967\n",
            "           6       0.87      0.87      0.87      4999\n",
            "           7       0.86      0.85      0.85      5231\n",
            "           8       0.93      0.89      0.91     22690\n",
            "           9       0.81      0.83      0.82      2886\n",
            "\n",
            "    accuracy                           0.86     54300\n",
            "   macro avg       0.82      0.84      0.83     54300\n",
            "weighted avg       0.86      0.86      0.86     54300\n",
            "\n",
            "Random Forest - Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.30      0.30      1155\n",
            "           1       0.23      0.25      0.24       452\n",
            "           2       0.52      0.50      0.51       529\n",
            "           3       0.62      0.66      0.64      1292\n",
            "           4       0.58      0.58      0.58       704\n",
            "           5       0.53      0.55      0.54       492\n",
            "           6       0.56      0.61      0.58      1250\n",
            "           7       0.54      0.58      0.56      1308\n",
            "           8       0.75      0.71      0.73      5672\n",
            "           9       0.49      0.48      0.48       721\n",
            "\n",
            "    accuracy                           0.60     13575\n",
            "   macro avg       0.51      0.52      0.52     13575\n",
            "weighted avg       0.61      0.60      0.60     13575\n",
            "\n",
            "\n",
            "XGBoost - Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.25      0.25      4622\n",
            "           1       0.16      0.37      0.23      1809\n",
            "           2       0.21      0.44      0.28      2116\n",
            "           3       0.35      0.43      0.39      5166\n",
            "           4       0.21      0.48      0.29      2814\n",
            "           5       0.22      0.53      0.31      1967\n",
            "           6       0.37      0.42      0.40      4999\n",
            "           7       0.40      0.42      0.41      5231\n",
            "           8       0.70      0.27      0.39     22690\n",
            "           9       0.30      0.37      0.33      2886\n",
            "\n",
            "    accuracy                           0.35     54300\n",
            "   macro avg       0.32      0.40      0.33     54300\n",
            "weighted avg       0.47      0.35      0.36     54300\n",
            "\n",
            "XGBoost - Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.17      0.16      1155\n",
            "           1       0.09      0.19      0.12       452\n",
            "           2       0.13      0.28      0.18       529\n",
            "           3       0.27      0.33      0.30      1292\n",
            "           4       0.15      0.35      0.21       704\n",
            "           5       0.15      0.37      0.22       492\n",
            "           6       0.28      0.32      0.30      1250\n",
            "           7       0.31      0.33      0.32      1308\n",
            "           8       0.64      0.23      0.34      5672\n",
            "           9       0.19      0.23      0.21       721\n",
            "\n",
            "    accuracy                           0.27     13575\n",
            "   macro avg       0.24      0.28      0.24     13575\n",
            "weighted avg       0.39      0.27      0.28     13575\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train and Predict for Logistic Regression (LR)\n",
        "y_train_pred_lr, y_test_pred_lr = train_and_predict(pipeline_lr, X_train_lr, y_train_lr, X_test_lr)\n",
        "compare_results(\"Logistic Regression\", y_train_lr, y_train_pred_lr, y_test_lr, y_test_pred_lr)\n",
        "\n",
        "# Train and Predict for Random Forest (RFC)\n",
        "y_train_pred_rf, y_test_pred_rf = train_and_predict(pipeline_rf, X_train_w2v, y_train_w2v, X_test_w2v)\n",
        "compare_results(\"Random Forest\", y_train_w2v, y_train_pred_rf, y_test_w2v, y_test_pred_rf)\n",
        "\n",
        "# Train and Predict for XGBoost (XGB)\n",
        "y_train_pred_xgb, y_test_pred_xgb = train_and_predict(pipeline_xgb, X_train_w2v, y_train_w2v, X_test_w2v)\n",
        "compare_results(\"XGBoost\", y_train_w2v, y_train_pred_xgb, y_test_w2v, y_test_pred_xgb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression (LR) results and model\n",
        "lr_results_and_model = {\n",
        "    'y_train_true_lr': y_train_lr,\n",
        "    'y_train_pred_lr': y_train_pred_lr,\n",
        "    'y_test_true_lr': y_test_lr,\n",
        "    'y_test_pred_lr': y_test_pred_lr,\n",
        "    'lr_model': pipeline_lr,\n",
        "}\n",
        "\n",
        "with open(save_path + 'logistic_regression_results_and_model.pkl', 'wb') as file:\n",
        "    pickle.dump(lr_results_and_model, file)\n",
        "\n",
        "# Random Forest (RFC) results and model\n",
        "rf_results_and_model = {\n",
        "    'y_train_true_rfc': y_train_w2v,\n",
        "    'y_train_pred_rfc': y_train_pred_rf,\n",
        "    'y_test_true_rfc': y_test_w2v,\n",
        "    'y_test_pred_rfc': y_test_pred_rf,\n",
        "    'rf_model': pipeline_rf,\n",
        "}\n",
        "\n",
        "with open(save_path + 'random_forest_results_and_model.pkl', 'wb') as file:\n",
        "    pickle.dump(rf_results_and_model, file)\n",
        "\n",
        "# XGBoost (XGB) results and model\n",
        "xgb_results_and_model = {\n",
        "    'y_train_true_xgb': y_train_w2v,\n",
        "    'y_train_pred_xgb': y_train_pred_xgb,\n",
        "    'y_test_true_xgb': y_test_w2v,\n",
        "    'y_test_pred_xgb': y_test_pred_xgb,\n",
        "    'xgb_model': pipeline_xgb,\n",
        "}\n",
        "\n",
        "with open(save_path + 'xgboost_results_and_model.pkl', 'wb') as file:\n",
        "    pickle.dump(xgb_results_and_model, file)\n",
        "\n",
        "print(\"Data and models saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmUXC6MJ6k0x",
        "outputId": "c5fcaa8a-658b-4cf8-fc0c-026c640091af"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data and models saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u1bb5DLzOP-"
      },
      "source": [
        "The categories we are most interested in are 3 (empathogen/entactogen), 4 (entheogen), and 8 (Psychedelics).\n",
        "\n",
        "And since we were targeting precision, it looks like our logestic regression performed best on the test set and our RFC performed best on the training set, which indicates overfitting. Let's see if we can improve our RFC model with some parameter tuning. We will use GridSearch CV to find the best parameters and then train and test our model with those:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm2fRmW9c5jQ",
        "outputId": "fdd761b1-7df8-4d55-f770-f793ad10cd15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Random Forest with hyperparameter tuning...\n"
          ]
        }
      ],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'clf__n_estimators': [100, 200, 500],\n",
        "    'clf__max_depth': [None, 10, 20, 30],\n",
        "    'clf__min_samples_split': [2, 5, 10],\n",
        "    'clf__min_samples_leaf': [1, 2, 4],\n",
        "    'clf__bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(pipeline_rf, param_grid, cv=5)\n",
        "\n",
        "print(\"\\nTraining Random Forest with hyperparameter tuning...\")\n",
        "# Perform grid search\n",
        "grid_search.fit(X_train_w2v, y_train_w2v)\n",
        "\n",
        "# Print the best parameters and the best score\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)\n",
        "\n",
        "# Predict on the train and test set using the best model\n",
        "y_train_pred_grid = grid_search.predict(X_train_w2v)\n",
        "y_test_pred_grid = grid_search.predict(X_test_w2v)\n",
        "\n",
        "print(\"Training completed with hyperparameter tuning.\")\n",
        "\n",
        "# Save the trained grid search model\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/Data/grid_search_rf_model.joblib\"\n",
        "dump(grid_search, path)\n",
        "print(f\"Model saved to {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D-onfQPVWp8"
      },
      "outputs": [],
      "source": [
        "from joblib import load\n",
        "\n",
        "# Path to the saved model\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/Data/grid_search_rf_model.joblib\"\n",
        "\n",
        "# Load the model\n",
        "grid_search_loaded = load(path)\n",
        "\n",
        "print(\"Model loaded from\", path)\n",
        "\n",
        "\n",
        "# Generate and print the classification report for both train and test\n",
        "print(\"Train Classification Report (with tuning):\")\n",
        "print(classification_report(y_train_w2v, y_train_pred_grid, zero_division=1))\n",
        "print(\"Test Classification Report (with tuning):\")\n",
        "print(classification_report(y_test_w2v, y_test_pred_grid, zero_division=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffmh53P2e1ax"
      },
      "source": [
        "Comparing the untuned results to the tuned results shows us that while the tuned results did better on the training data: Entactogen/Empathogen (84/85), Entheogen (83/86), Psychedelic (93/94), they ended up doing worse on our test set (68/61), (63/55), (79/78). So we will stick with our original model to explore the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iORxlDXszOP_"
      },
      "outputs": [],
      "source": [
        "# Label the categories\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(df['drug_category'])\n",
        "drug_categories = encoder.classes_\n",
        "\n",
        "# Generate confusion matrices for test\n",
        "cm_test = confusion_matrix(y_test_w2v, y_test_pred_rf)\n",
        "\n",
        "# Plot confusion matrix for test set\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm_test, annot=True, xticklabels=drug_categories, yticklabels=drug_categories, fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like our model was most likely to label a psychedelic as a cannabinoid, entactogen/empathogen, or an entheogen, and least likely to label it a dissociative, opiod, or stimulat, which is what we would expect! Now let's check out some of the feature importances to see what it is our model thinks is valuable for making its predictions. We will use LIME. To do so, means we need to define a prediction probability function. This function should take a list of texts and return the predicted probabilities for each class for each text. It will use our Word2Vec model and our trained RFC pipeline."
      ],
      "metadata": {
        "id": "JSp_AqB1Y7WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipeline_rf)"
      ],
      "metadata": {
        "id": "kAlOwC3Ojh_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Vn0EXfaTzOP_"
      },
      "outputs": [],
      "source": [
        "# Load Word2Vec model\n",
        "#word2vec_model_path = \"/content/drive/MyDrive/Colab Notebooks/Data/word2vec_model.model\"\n",
        "#word2vec = Word2Vec.load(word2vec_model_path)\n",
        "\n",
        "def preprocess_func(texts):\n",
        "    transformed_texts = []\n",
        "    for text in texts:\n",
        "        # Convert the string representation of the list into an actual list\n",
        "        processed_report = literal_eval(text)\n",
        "\n",
        "        # Flatten the list\n",
        "        processed_report = [word for sublist in processed_report for word in sublist]\n",
        "\n",
        "        # Convert report into a vector\n",
        "        report_vec = report_to_vector(processed_report, word2vec)\n",
        "\n",
        "        transformed_texts.append(report_vec)\n",
        "\n",
        "    return np.vstack(transformed_texts)\n",
        "\n",
        "def predict_proba_func(texts):\n",
        "    def report_to_vector_inner(report, model):\n",
        "        report_vec = []\n",
        "        numw = 0\n",
        "        for word in report:\n",
        "            try:\n",
        "                if numw == 0:\n",
        "                    report_vec = model.wv[word]\n",
        "                else:\n",
        "                    report_vec = np.add(report_vec, model.wv[word])\n",
        "                numw += 1\n",
        "            except:\n",
        "                pass\n",
        "        return np.asarray(report_vec) / numw if numw != 0 else np.zeros(model.vector_size)\n",
        "\n",
        "    transformed_texts = preprocess_func(texts)\n",
        "    return pipeline_rf.predict_proba(transformed_texts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we create an explainer using LIME, then choose an instance to explain, and then have the model explain."
      ],
      "metadata": {
        "id": "_K3k8NBJd92s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a LimeTextExplainer\n",
        "explainer = LimeTextExplainer(class_names=label_encoder.classes_, split_expression=r'\\W+') # Split by words\n",
        "\n",
        "# Filter the DataFrame to include only rows labeled as 'Psychedelic'\n",
        "psychedelic_df = df[df['drug_category'] == 'Psychedelic']\n",
        "\n",
        "# Select a random index from the filtered DataFrame\n",
        "index_to_explain = randint(0, len(psychedelic_df['processed_report']) - 1)\n",
        "\n",
        "# Get the processed report at the chosen index\n",
        "instance = psychedelic_df['processed_report'].iloc[index_to_explain]\n",
        "\n",
        "# Convert the processed report to a single string\n",
        "instance_as_string = ' '.join(instance)\n",
        "\n",
        "# Find the index of 'Psychedelic' in the classes\n",
        "class_index_to_explain = list(label_encoder.classes_).index('Psychedelic')\n",
        "\n",
        "# Explain the prediction for the chosen instance, focusing on the class_index_to_explain\n",
        "explanation = explainer.explain_instance(instance_as_string, predict_proba_func, labels=[class_index_to_explain])\n",
        "\n",
        "# Show the explanation in the notebook\n",
        "explanation.show_in_notebook()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "8RKzRHNhehda",
        "outputId": "ea9fa4b8-068c-4c93-9a88-74d27ae55b55"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-e17cb07c2111>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Explain the prediction for the chosen instance, focusing on the class_index_to_explain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mexplanation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_as_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_proba_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_index_to_explain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Show the explanation in the notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/lime_text.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    411\u001b[0m                                         mask_string=self.mask_string))\n\u001b[1;32m    412\u001b[0m         \u001b[0mdomain_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextDomainMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         data, yss, distances = self.__data_labels_distances(\n\u001b[0m\u001b[1;32m    414\u001b[0m             \u001b[0mindexed_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             distance_metric=distance_metric)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/lime_text.py\u001b[0m in \u001b[0;36m__data_labels_distances\u001b[0;34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minactive\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0minverse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_removing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minactive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverse_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-c1b65806b1b9>\u001b[0m in \u001b[0;36mpredict_proba_func\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtransformed_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, **predict_proba_params)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_proba_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_final_estimator_has\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decision_function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \"\"\"\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from random import randint\n",
        "\n",
        "# Extract the RFC model from the loaded results\n",
        "rf_model = random_forest_results_and_model['rf_model']\n",
        "\n",
        "# Define a prediction probability function compatible with the RFC model\n",
        "def predict_proba_func(texts):\n",
        "    return rf_model.predict_proba(vectorize_reports([text.split() for text in texts], word2vec))\n",
        "\n",
        "# Initialize a LimeTextExplainer\n",
        "explainer = LimeTextExplainer(class_names=label_encoder.classes_, split_expression=r'\\W+') # Split by words\n",
        "\n",
        "# Filter the DataFrame to include only rows labeled as 'Psychedelic'\n",
        "psychedelic_df = df[df['drug_category'] == 'Psychedelic']\n",
        "\n",
        "# Select a random index from the filtered DataFrame\n",
        "index_to_explain = randint(0, len(psychedelic_df['processed_report']) - 1)\n",
        "\n",
        "# Get the processed report at the chosen index\n",
        "instance = psychedelic_df['processed_report'].iloc[index_to_explain]\n",
        "\n",
        "# Convert the processed report to a single string\n",
        "instance_as_string = ' '.join(instance)\n",
        "\n",
        "# Find the index of 'Psychedelic' in the classes\n",
        "class_index_to_explain = list(label_encoder.classes_).index('Psychedelic')\n",
        "\n",
        "# Explain the prediction for the chosen instance, focusing on the class_index_to_explain\n",
        "explanation = explainer.explain_instance(instance_as_string, predict_proba_func, labels=[class_index_to_explain])\n",
        "\n",
        "# Show the explanation in the notebook\n",
        "explanation.show_in_notebook()\n"
      ],
      "metadata": {
        "id": "dMzoL0mR8_I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCbQzCz9zOQA"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame to hold data\n",
        "error_analysis_df = pd.DataFrame(X_test, columns=feature_names) # assuming feature_names contains your feature names\n",
        "error_analysis_df['true'] = y_test\n",
        "error_analysis_df['predicted'] = y_test_pred_rf\n",
        "\n",
        "# Plot instances where prediction is correct vs incorrect\n",
        "sns.scatterplot(x='feature1', y='feature2', hue='true', style=(error_analysis_df['true'] == error_analysis_df['predicted']), data=error_analysis_df)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef, balanced_accuracy_score\n",
        "\n",
        "mcc = matthews_corrcoef(y_test, y_test_pred_rf)\n",
        "balanced_acc = balanced_accuracy_score(y_test, y_test_pred_rf)\n",
        "\n",
        "print(\"Matthews correlation coefficient:\", mcc)\n",
        "print(\"Balanced accuracy score:\", balanced_acc)\n"
      ],
      "metadata": {
        "id": "GB0KL0Suz9P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jAI2Q5eiWxv5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}